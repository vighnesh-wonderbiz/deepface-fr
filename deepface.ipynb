{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62d54f-529b-4953-93ec-72a3b760f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepface opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8968723d-d37d-4417-a192-e8ae61adff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sqlite3\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bdc51ac-f842-4d72-a4de-32041a492b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created or already exist.\n"
     ]
    }
   ],
   "source": [
    "def create_tables():\n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS Users (\n",
    "                    Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    Name TEXT NOT NULL,\n",
    "                    FaceEncoding BLOB\n",
    "                )\n",
    "            ''')\n",
    "            # Create attendance table\n",
    "            cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS Attendance (\n",
    "                    Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    UserId INTEGER,\n",
    "                    Timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                    FOREIGN KEY(UserId) REFERENCES Users(Id)\n",
    "                )\n",
    "            ''')\n",
    "            print(\"Tables created or already exist.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "create_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aff870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(frames):\n",
    "    face_images = []\n",
    "    for frame in frames:\n",
    "        try:\n",
    "            result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=True)\n",
    "            if result:\n",
    "                face_data = result[0]['region']\n",
    "                x, y, w, h = face_data['x'], face_data['y'], face_data['w'], face_data['h']\n",
    "                face_image = frame[y:y+h, x:x+w]\n",
    "                face_images.append(face_image)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during face detection: {e}\")\n",
    "    \n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12423c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_encoding(face_images):\n",
    "    encodings = []\n",
    "    for face_image in face_images:\n",
    "        try:\n",
    "            encoding = DeepFace.represent(face_image, model_name='VGG-Face', enforce_detection=False)[0]\n",
    "            encodings.append(encoding)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during encoding: {e}\")\n",
    "    \n",
    "    if encodings:\n",
    "        mean_encoding = np.mean(encodings, axis=0)\n",
    "        return mean_encoding\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0bcb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_images(name, num_images=5, interval=1):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frames = []\n",
    "    \n",
    "    print(f\"Preparing to capture {num_images} images. Please look at the camera.\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        time.sleep(interval)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(f\"Failed to capture image {i+1}.\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return None\n",
    "        \n",
    "        image_path = f\"./{name}_{i+1}.jpg\"\n",
    "        cv2.imwrite(image_path, frame)\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"{num_images} images captured and saved.\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb423173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def capture_images(name, num_images=5, interval=3):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frames = []\n",
    "    \n",
    "    print(f\"Preparing to capture {num_images} images. Please look at the camera.\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Failed to capture image {i+1}.\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return None\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            remaining_time = interval - elapsed_time\n",
    "\n",
    "            if remaining_time > 0:\n",
    "                cv2.putText(frame, f\"Capturing in {int(remaining_time) + 1} seconds...\",\n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('Capture Timer', frame)\n",
    "                cv2.waitKey(1)\n",
    "            else:\n",
    "                image_path = f\"./{name}_{i+1}.jpg\"\n",
    "                cv2.imwrite(image_path, frame)\n",
    "                frames.append(frame)\n",
    "                print(f\"Captured image {i+1}.\")\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"{num_images} images captured and saved.\")\n",
    "    return frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50139f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(frames):\n",
    "    face_images = []\n",
    "    for frame in frames:\n",
    "        try:\n",
    "            result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "            if result:\n",
    "                face_data = result[0]['region']\n",
    "                x, y, w, h = face_data['x'], face_data['y'], face_data['w'], face_data['h']\n",
    "                face_image = frame[y:y+h, x:x+w]\n",
    "                face_images.append(face_image)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during face detection: {e}\")\n",
    "    \n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e91e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_encoding(face_images):\n",
    "    encodings = []\n",
    "    for face_image in face_images:\n",
    "        try:\n",
    "            encoding = DeepFace.represent(face_image, model_name='VGG-Face', enforce_detection=False)[0]\n",
    "            encodings.append(encoding[\"embedding\"])\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during encoding: {e}\")\n",
    "    \n",
    "    if encodings:\n",
    "        mean_encoding = np.mean(encodings, axis=0)\n",
    "        return mean_encoding\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11825a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to capture 5 images. Please look at the camera.\n",
      "Captured image 1.\n",
      "Captured image 2.\n",
      "Captured image 3.\n",
      "Captured image 4.\n",
      "Captured image 5.\n",
      "5 images captured and saved.\n",
      "An error occurred during face detection: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "An error occurred during face detection: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "An error occurred during face detection: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "User rohit added successfully.\n",
      "Temporary image file rohit_1.jpg deleted.\n",
      "Temporary image file rohit_2.jpg deleted.\n",
      "Temporary image file rohit_3.jpg deleted.\n",
      "Temporary image file rohit_4.jpg deleted.\n",
      "Temporary image file rohit_5.jpg deleted.\n",
      "All temporary files deleted.\n"
     ]
    }
   ],
   "source": [
    "def insert_user():\n",
    "    name = input(\"Enter the user's name: \")\n",
    "    frames = capture_images(name)\n",
    "    \n",
    "    if frames is None:\n",
    "        return\n",
    "    \n",
    "    face_images = detect_and_crop_faces(frames)\n",
    "    \n",
    "    if not face_images:\n",
    "        print(\"No face detected in the images. Please try again.\")\n",
    "        for i in range(len(frames)):\n",
    "            os.remove(f\"./{name}_{i+1}.jpg\")\n",
    "        return\n",
    "    mean_encoding = calculate_mean_encoding(face_images)\n",
    "    \n",
    "    if mean_encoding is None:\n",
    "        print(\"Failed to encode faces. Please try again.\")\n",
    "        for i in range(len(frames)):\n",
    "            os.remove(f\"./{name}_{i+1}.jpg\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('INSERT INTO Users (Name, FaceEncoding) VALUES (?, ?)', (name, pickle.dumps(mean_encoding)))\n",
    "            conn.commit()\n",
    "            print(f\"User {name} added successfully.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        for i in range(len(frames)):\n",
    "            # os.remove(f\"./{name}_{i+1}.jpg\")\n",
    "            print(f\"Temporary image file {name}_{i+1}.jpg deleted.\")\n",
    "        print(\"All temporary files deleted.\")\n",
    "\n",
    "insert_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f89fa343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_users():\n",
    "    users = {}\n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT * FROM Users')\n",
    "            rows = cursor.fetchall()\n",
    "            for row in rows:\n",
    "                Id, Name, FaceEncoding = row\n",
    "                users[Id] = (Name, pickle.loads(FaceEncoding))\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b2ea4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_and_mark_attendance(frame, users):\n",
    "    try:\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_region = frame[y:y+h, x:x+w]\n",
    "            rgb_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            result = DeepFace.represent(img_path=rgb_face, model_name='VGG-Face', enforce_detection=False)\n",
    "            \n",
    "            if not result or not isinstance(result, list) or not isinstance(result[0], dict):\n",
    "                print(\"Failed to retrieve valid embeddings for face.\")\n",
    "                continue\n",
    "            \n",
    "            new_embedding = result[0]['embedding']  \n",
    "            new_embedding = np.array(new_embedding)\n",
    "            \n",
    "            recognized = False\n",
    "            for Id, (name, stored_embedding) in users.items():\n",
    "                stored_embedding = np.array(stored_embedding)\n",
    "                distance = np.linalg.norm(new_embedding - stored_embedding)\n",
    "                print(distance)\n",
    "                if distance <1.0:  # Adjust threshold as needed\n",
    "                    print(f\"Recognized {name}\")\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                    recognized = True\n",
    "                    break\n",
    "            \n",
    "            if not recognized:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Unknown\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1769754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5241788960786032\n",
      "Recognized Vighnesh\n",
      "1.2164067926001754\n",
      "0.8194832409213104\n",
      "Recognized rohit\n",
      "0.562238270359747\n",
      "Recognized Vighnesh\n",
      "1.1949564701830653\n",
      "0.7675230522015901\n",
      "Recognized rohit\n",
      "0.5670384151343021\n",
      "Recognized Vighnesh\n",
      "1.1680165819536572\n",
      "0.8037055404350778\n",
      "Recognized rohit\n",
      "0.5620946448145018\n",
      "Recognized Vighnesh\n",
      "1.174238633362404\n",
      "0.8470723132455067\n",
      "Recognized rohit\n",
      "0.7636433482458885\n",
      "Recognized Vighnesh\n",
      "1.182996067394699\n",
      "0.779459973822366\n",
      "Recognized rohit\n",
      "0.7336034273421083\n",
      "Recognized Vighnesh\n",
      "0.7566878192023347\n",
      "Recognized Vighnesh\n",
      "0.6802579806637611\n",
      "Recognized Vighnesh\n",
      "0.6612131040904491\n",
      "Recognized Vighnesh\n",
      "1.2001260832990965\n",
      "0.6963451699887541\n",
      "Recognized rohit\n",
      "0.7192931682787215\n",
      "Recognized Vighnesh\n",
      "0.6494140091143065\n",
      "Recognized Vighnesh\n",
      "1.1777410039368459\n",
      "0.8629625096823845\n",
      "Recognized rohit\n",
      "0.620612766759803\n",
      "Recognized Vighnesh\n",
      "1.2019220219145037\n",
      "1.314360145626125\n",
      "0.6480309288495361\n",
      "Recognized Vighnesh\n",
      "0.6202700651260954\n",
      "Recognized Vighnesh\n",
      "0.6648556370632662\n",
      "Recognized Vighnesh\n",
      "1.2010939812451422\n",
      "1.316276884918641\n",
      "1.2425847740406901\n",
      "0.7103521221493055\n",
      "Recognized rohit\n",
      "0.6021988154990274\n",
      "Recognized Vighnesh\n",
      "1.197956291386784\n",
      "0.7622968236513429\n",
      "Recognized rohit\n",
      "0.6872082077036539\n",
      "Recognized Vighnesh\n",
      "1.1699943951270981\n",
      "0.8313098847647977\n",
      "Recognized rohit\n",
      "0.7081345228799738\n",
      "Recognized Vighnesh\n",
      "0.6770307943566686\n",
      "Recognized Vighnesh\n",
      "1.223503267311716\n",
      "0.881952695415461\n",
      "Recognized rohit\n",
      "1.2020311965175463\n",
      "1.3100762474815775\n",
      "0.5823991577772537\n",
      "Recognized Vighnesh\n",
      "0.6207963810054692\n",
      "Recognized Vighnesh\n",
      "1.2057153798648197\n",
      "0.8574589158931263\n",
      "Recognized rohit\n",
      "0.6639205686182648\n",
      "Recognized Vighnesh\n",
      "1.2043526816211028\n",
      "0.9809327551099036\n",
      "Recognized rohit\n",
      "0.6343327555861282\n",
      "Recognized Vighnesh\n",
      "0.6082770275014283\n",
      "Recognized Vighnesh\n",
      "1.1452939671164843\n",
      "0.9466929897166223\n",
      "Recognized rohit\n",
      "1.1626523063311183\n",
      "1.0254877242730325\n",
      "0.6033472727189372\n",
      "Recognized Vighnesh\n",
      "0.6263827750302008\n",
      "Recognized Vighnesh\n",
      "0.5942476151631108\n",
      "Recognized Vighnesh\n",
      "0.6534877889108565\n",
      "Recognized Vighnesh\n",
      "1.2120268584268485\n",
      "1.2866720350646002\n",
      "0.6411630100882678\n",
      "Recognized Vighnesh\n",
      "0.5927365988456771\n",
      "Recognized Vighnesh\n",
      "0.603631520729594\n",
      "Recognized Vighnesh\n",
      "0.5790051599923499\n",
      "Recognized Vighnesh\n",
      "0.6103596672751395\n",
      "Recognized Vighnesh\n",
      "1.2149731011804092\n",
      "0.9328487132821222\n",
      "Recognized rohit\n",
      "0.6637590919849279\n",
      "Recognized Vighnesh\n",
      "0.709302759713238\n",
      "Recognized Vighnesh\n",
      "1.17468066363715\n",
      "0.920237061955758\n",
      "Recognized rohit\n",
      "0.6665156862285154\n",
      "Recognized Vighnesh\n",
      "1.1814967440648703\n",
      "0.9332274699603942\n",
      "Recognized rohit\n",
      "0.6069974807430003\n",
      "Recognized Vighnesh\n",
      "0.5868187901040854\n",
      "Recognized Vighnesh\n",
      "1.2149988091952781\n",
      "1.3203360098949328\n",
      "0.6133416391662627\n",
      "Recognized Vighnesh\n",
      "0.590584434900572\n",
      "Recognized Vighnesh\n",
      "0.5968534834038087\n",
      "Recognized Vighnesh\n",
      "0.5821385832248882\n",
      "Recognized Vighnesh\n",
      "0.700490804634331\n",
      "Recognized Vighnesh\n",
      "0.6235427758943803\n",
      "Recognized Vighnesh\n",
      "1.1684320328150666\n",
      "1.0266717479266192\n",
      "0.634126960093465\n",
      "Recognized Vighnesh\n",
      "1.1648870461625744\n",
      "1.0451269253751354\n",
      "0.597450286817066\n",
      "Recognized Vighnesh\n",
      "1.1945718738548743\n",
      "1.002135209391202\n",
      "0.5780171563128416\n",
      "Recognized Vighnesh\n",
      "1.1644686322104005\n",
      "0.9472846579766282\n",
      "Recognized rohit\n",
      "0.561624134388713\n",
      "Recognized Vighnesh\n",
      "0.5761072953643566\n",
      "Recognized Vighnesh\n",
      "0.5640465125015356\n",
      "Recognized Vighnesh\n",
      "0.5470222059594515\n",
      "Recognized Vighnesh\n",
      "0.5724263354509808\n",
      "Recognized Vighnesh\n",
      "1.183068056107688\n",
      "0.8898895459182855\n",
      "Recognized rohit\n",
      "0.6057386010533483\n",
      "Recognized Vighnesh\n",
      "0.6790234826261332\n",
      "Recognized Vighnesh\n",
      "1.2308567399312487\n",
      "0.8889401995965542\n",
      "Recognized rohit\n",
      "0.6410634711711004\n",
      "Recognized Vighnesh\n",
      "0.631096066790267\n",
      "Recognized Vighnesh\n",
      "1.2259899787310484\n",
      "0.9465267412372939\n",
      "Recognized rohit\n",
      "1.2205964436464976\n",
      "0.7242783424617552\n",
      "Recognized rohit\n",
      "0.5599313920049651\n",
      "Recognized Vighnesh\n",
      "0.5902273257723144\n",
      "Recognized Vighnesh\n",
      "0.5992391349130913\n",
      "Recognized Vighnesh\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    users = load_users()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        recognize_and_mark_attendance(frame, users)\n",
    "        \n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd1741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f669b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_image(name):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print(\"Preparing to capture image. Please look at the camera.\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to capture image.\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return None, None\n",
    "    \n",
    "    image_path = \"./\"+name + \".jpg\"\n",
    "    cv2.imwrite(image_path, frame)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Image captured and saved to {image_path}.\")\n",
    "    return image_path, frame\n",
    "\n",
    "def detect_and_crop_face(image_path, frame):\n",
    "    try:\n",
    "        result = DeepFace.analyze(image_path, actions=['emotion'], enforce_detection=True)\n",
    "        if result:\n",
    "            face_data = result[0]['region']\n",
    "            x, y, w, h = face_data['x'], face_data['y'], face_data['w'], face_data['h']\n",
    "            face_image = frame[y:y+h, x:x+w]\n",
    "            face_cutout_path = 'face_cutout.jpg'\n",
    "            cv2.imwrite(face_cutout_path, face_image)\n",
    "            print(f\"Face detected and cutout saved to {face_cutout_path}.\")\n",
    "            return face_cutout_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during face detection: {e}\")\n",
    "    return None\n",
    "\n",
    "def insert_user():\n",
    "    name = input(\"Enter the user's name: \")\n",
    "    image_path, frame = capture_image(name)\n",
    "    if image_path is None:\n",
    "        return\n",
    "    face_cutout_path = detect_and_crop_face(image_path, frame)\n",
    "    if face_cutout_path is None:\n",
    "        print(\"No face detected in the image. Please try again.\")\n",
    "        os.remove(image_path)\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            encoding = DeepFace.represent(face_cutout_path, model_name='VGG-Face', enforce_detection=False)[0]\n",
    "            cursor.execute('INSERT INTO Users (Name, FaceEncoding) VALUES (?, ?)', (name, pickle.dumps(encoding)))\n",
    "            conn.commit()\n",
    "            print(f\"User {name} added successfully.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "            print(f\"Temporary image file {image_path} deleted.\")\n",
    "        if os.path.exists(face_cutout_path):\n",
    "            os.remove(face_cutout_path)\n",
    "            print(f\"Face cutout file {face_cutout_path} deleted.\")\n",
    "\n",
    "insert_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e24637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-08-05 17:57:40 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:42 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:43 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:44 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:45 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:47 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "24-08-05 17:57:48 - ⚠️ Function detectFace is deprecated. Use extract_faces instead.\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "An error occurred: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n"
     ]
    }
   ],
   "source": [
    "def load_users():\n",
    "    users = {}\n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT * FROM Users')\n",
    "            rows = cursor.fetchall()\n",
    "            for row in rows:\n",
    "                Id, Name, FaceEncoding = row\n",
    "                users[Id] = (Name, pickle.loads(FaceEncoding))\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return users\n",
    "\n",
    "def recognize_and_mark_attendance(frame, users):\n",
    "    try:\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = DeepFace.detectFace(rgb_frame, detector_backend='mtcnn', enforce_detection=False)\n",
    "        if results is None:\n",
    "            print(\"No faces detected.\")\n",
    "            return\n",
    "        for result in results:\n",
    "            print(result)\n",
    "            new_embedding = result['embedding']  # Extract embedding from the result\n",
    "            face_region = result['region']  # Extract face region\n",
    "            x, y, w, h = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n",
    "            \n",
    "            # Convert new_embedding to a numpy array\n",
    "            new_embedding = np.array(new_embedding)\n",
    "            \n",
    "            recognized = False\n",
    "            for Id, (name, stored_embedding) in users.items():\n",
    "                stored_embedding = np.array(stored_embedding['embedding'])\n",
    "                print(new_embedding)\n",
    "                print(stored_embedding)\n",
    "                distance = np.linalg.norm(new_embedding - stored_embedding)\n",
    "                \n",
    "                if distance < 1.0:  # Adjust threshold as needed\n",
    "                    print(f\"Recognized {name}\")\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                    recognized = True\n",
    "                    break\n",
    "            \n",
    "            if not recognized:\n",
    "                # Draw bounding box and label for unrecognized face\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Unknown\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def main():\n",
    "    users = load_users()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        recognize_and_mark_attendance(frame, users)\n",
    "        \n",
    "        # Display the annotated frame\n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bace1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3232652384561006\n",
      "1.2330103579613887\n",
      "1.2600069077120624\n",
      "0.6765102401285111\n",
      "Recognized nimesh\n",
      "1.314276477669293\n",
      "1.2319964351500032\n",
      "1.255991111985867\n",
      "0.5715820542682832\n",
      "Recognized nimesh\n",
      "1.3284527160795694\n",
      "1.2576476722092442\n",
      "1.265381790528269\n",
      "0.6833516980310229\n",
      "Recognized nimesh\n",
      "1.3228067634765959\n",
      "1.2318720264357599\n",
      "1.2583896283707094\n",
      "0.5903134548820611\n",
      "Recognized nimesh\n",
      "1.0195663429700093\n",
      "1.095718114488874\n",
      "1.3016673607360978\n",
      "1.315054053274347\n",
      "Face not recognized\n",
      "1.3432298628252146\n",
      "1.2594811733084885\n",
      "1.2887568692590432\n",
      "0.71200385309513\n",
      "Recognized nimesh\n",
      "1.0090549383543044\n",
      "0.9946091007913768\n",
      "Recognized sharan\n",
      "1.3369538599846347\n",
      "1.2537944303906374\n",
      "1.2902619190769808\n",
      "0.7221736444145481\n",
      "Recognized nimesh\n",
      "0.9757377435778818\n",
      "Recognized Vighnesh\n",
      "0.9651748258143288\n",
      "Recognized Vighnesh\n",
      "1.3345387410599028\n",
      "1.2392741356328216\n",
      "1.2705893130581256\n",
      "0.5947067122228329\n",
      "Recognized nimesh\n"
     ]
    }
   ],
   "source": [
    "def load_users():\n",
    "    users = {}\n",
    "    try:\n",
    "        with sqlite3.connect('emp.db') as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT * FROM Users')\n",
    "            rows = cursor.fetchall()\n",
    "            for row in rows:\n",
    "                Id, Name, FaceEncoding = row\n",
    "                # Ensure FaceEncoding is deserialized from bytes\n",
    "                users[Id] = (Name, pickle.loads(FaceEncoding))\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return users\n",
    "\n",
    "def recognize_and_mark_attendance(frame, users):\n",
    "    try:\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get the embeddings for the current frame\n",
    "        result = DeepFace.represent(img_path=rgb_frame, model_name='VGG-Face', enforce_detection=False)\n",
    "        \n",
    "        if not result or not isinstance(result, list):\n",
    "            print(\"Failed to retrieve embeddings.\")\n",
    "            return False\n",
    "        new_embedding = result[0][\"embedding\"]\n",
    "        \n",
    "        new_embedding = np.array(new_embedding)\n",
    "        for Id, (name, stored_embedding) in users.items():\n",
    "            stored_embedding = np.array(stored_embedding[\"embedding\"])\n",
    "            distance = np.linalg.norm(new_embedding - stored_embedding)\n",
    "            print(distance)\n",
    "            if distance < 1.0:\n",
    "                print(f\"Recognized {name}\")\n",
    "                return True\n",
    "        \n",
    "        print(\"Face not recognized\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    users = load_users()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        recognize_and_mark_attendance(frame, users)\n",
    "        \n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siamese-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
